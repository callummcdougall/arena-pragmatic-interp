{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2217a96",
   "metadata": {},
   "source": [
    "```python\n",
    "[\n",
    "    {\"title\": \"CoT Infrastructure & Sentence Taxonomy\", \"icon\": \"1-circle-fill\", \"subtitle\": \"(30%)\"},\n",
    "    {\"title\": \"Black-box Analysis\", \"icon\": \"2-circle-fill\", \"subtitle\": \"(30%)\"},\n",
    "    {\"title\": \"White-box Methods\", \"icon\": \"3-circle-fill\", \"subtitle\": \"(40%)\"},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38bd7d",
   "metadata": {},
   "source": [
    "# [1.6.5] LLM Psychology & Persona Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b9536",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/refs/heads/main/img/header-65.png\" width=\"350\">\n",
    "\n",
    "*Note - this content is subject to change depending on how much Anthropic publish about their [soul doc](https://simonwillison.net/2025/Dec/2/claude-soul-document/) over the coming weeks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9859de",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbadb7",
   "metadata": {},
   "source": [
    "Most exercises in this chapter have dealt with LLMs at quite a low level of abstraction; as mechanisms to perform certain tasks (e.g. indirect object identification, in-context antonym learning, or algorithmic tasks like predicting legal Othello moves). However, if we want to study the characteristics of current LLMs which might have alignment relevance, we need to use a higher level of abstraction. LLMs often exhibit \"personas\" that can shift unexpectedly - sometimes dramatically (see Sydney, Grok's \"MechaHitler\" persona, or [Tim Hua's work](https://www.lesswrong.com/posts/iGF7YcnQkEbwvYLPA/ai-induced-psychosis-a-shallow-investigation) on AI-induced psychosis). These personalities are clearly shaped through training and prompting, but exactly why remains a mystery.\n",
    "\n",
    "In this section, we'll explore one approach for studying these kinds of LLM behaviours - **model psychiatry**. This sits at the intersection of evals (behavioural observation) and mechanistic interpretability (understanding internal representations / mechanisms). We aim to use interp tools to understand & intervene on behavioural traits.\n",
    "\n",
    "The main focus will be on two different papers from Anthropic. First, we'll replicate the results from [The assistant axis: situating and stabilizing the character of large language models](https://www.anthropic.com/research/assistant-axis), which studies the \"persona space\" in internal model activations, and situates the \"Assistant persona\" within that space. The paper also introduces a method called **activation capping**, which identifies the normal range of activation intensity along this \"Assistant Axis\" and caps the model's activations when it would otherwise exceed it, which reduces the model's susceptibility to persona-based jailbreaks. Then, we'll move to the paper [Persona vectors: Monitoring and controlling character traits in language models](https://www.anthropic.com/research/persona-vectors) which predates the Assistant Axis paper but is broader and more methodologically sophisticated, proposing an automated pipeline for identifying persona vectors corresponding to specific kinds of undesireable personality shifts.\n",
    "\n",
    "This section is (compared to many others in this chapter) very recent work, and there are still many uncertainties and unanswered questions! We'll suggest several bonus exercises or areas for further reading / exploration as we move through these exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a0ce7",
   "metadata": {},
   "source": [
    "## Content & Learning Objectives\n",
    "\n",
    "### 1️⃣ Mapping Persona Space\n",
    "\n",
    "You'll start by understanding the core methodology from the [Assistant Axis](https://www.anthropic.com/research/assistant-axis) paper. You'll load Gemma 27b with activation caching utilities, and extract vectors corresponding to several different personas spanning from \"helpful\" to \"fantastical\".\n",
    "\n",
    "> ##### Learning Objectives\n",
    "> \n",
    "> * Understand the persona space mapping explored by the Assistant Axis paper\n",
    "> * Given a persona name, generate a system prompt and collect responses to a diverse set of questions, to extract a mean activation vector for that persona\n",
    "> * Briefly study the geometry of these persona vectors using PCA and cosine similarity\n",
    "\n",
    "### 2️⃣ Steering along the Assistant Axis\n",
    "\n",
    "Now that you've extracted these persona vectors, you should be able to use the Assistant Axis to detect drift and intervene via **activation capping**. As case studies, we'll use some of the dialogues saved out by Tim Hua in his investigation of AI-induced psychosis (link to GitHub repo [here](https://github.com/tim-hua-01/ai-psychosis)). By the end of this section, you should be able to steer to mitigate these personality shifts without kneecapping model capabilities.\n",
    "\n",
    "> ##### Learning Objectives\n",
    "> \n",
    "> * Steer towards directions you found in the previous section, to increase model willingness to adopt alternative personas\n",
    "> * Understand how to use the Assistant Axis to detect drift and intervene via **activation capping**\n",
    "> * Apply this technique to mitigate personality shifts in AI models (measuring the harmful response rate with / without capping)\n",
    "\n",
    "### 3️⃣ Contrastive Prompting\n",
    "\n",
    "Here, we move onto the [Persona Vectors](https://www.anthropic.com/research/persona-vectors) paper. You'll move from the global persona structure to surgical trait-specific vectors, exploring how to extract these vectors using contrastive prompt pairs.\n",
    "\n",
    "> ##### Learning Objectives\n",
    "> \n",
    "> * Understand the automated artifact pipeline for extracting persona vectors using contrastive prompts\n",
    "> * Implement this pipeline (including autoraters for trait scoring) to extract \"sycophancy\" steering vectors\n",
    "> * Learn how to identify the best layers trait extration\n",
    "> * Interpret these sycophancy vectors using Gemma sparse autoencoders\n",
    "\n",
    "### 4️⃣ Steering with Persona Vectors\n",
    "\n",
    "Finally, you'll validate your extracted trait vectors through steering as well as projection-based monitoring. \n",
    "\n",
    "> ##### Learning Objectives\n",
    "> \n",
    "> * Complete your artifact pipeline by implementing persona steering\n",
    "> * Repeat this full pipeline for \"hallucination\" and \"evil\", as well as for any additional traits you choose to study\n",
    "> * Study the geometry of trait vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac72d88",
   "metadata": {},
   "source": [
    "## Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ed773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f6393",
   "metadata": {},
   "source": [
    "# 1️⃣ Mapping Persona Space\n",
    "\n",
    "First text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e6850",
   "metadata": {},
   "source": [
    "# 2️⃣ Steering along the Assistant Axis\n",
    "\n",
    "First text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7d04a",
   "metadata": {},
   "source": [
    "# 3️⃣ Contrastive Prompting\n",
    "\n",
    "First text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90de797",
   "metadata": {},
   "source": [
    "# 4️⃣ Steering with Persona Vectors\n",
    "\n",
    "First text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31ecef",
   "metadata": {},
   "source": [
    "## ☆ Bonus\n",
    "\n",
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
